% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pi_maxl.R
\name{compute_pi_ln_maxl}
\alias{compute_pi_ln_maxl}
\title{Maximize the RP log likelihood for given data N}
\usage{
compute_pi_ln_maxl(
  u,
  N,
  init_pi = rep(1/u$n_orders, u$n_orders),
  delta = 1e-04,
  epsilon = 1e-08,
  n_max_iter = 15000,
  beta = 0.95,
  debug = FALSE,
  doplot = FALSE
)
}
\arguments{
\item{u}{List with precomputed information about choice universes
of size n, created using \code{\link[=create_universe]{create_universe()}}}

\item{N}{Matrix containing observed choice counts in a choice experiment.}

\item{init_pi}{Starting value for vector pi that defaults to the discrete uniform distriubtion.}

\item{delta}{Parameter of a halt condition. If the range of log likelihood gradient values}

\item{epsilon}{Lowest value of pi that is considered distinct from zero.}

\item{n_max_iter}{Maximum number of iterations}

\item{beta}{A momemtum parameter}

\item{debug}{A flag that should normally be set to FALSE. If TRUE, some diagnostic
information is displayed to the screen.}

\item{doplot}{A flag that should normally be set to FALSE. If TRUE, a diagnostic
plots is displayed.}
}
\value{
A list with the following elements
\describe{
\item{pi}{Final value of the probability vector pi}
\item{ln_maxl}{Final value of the RP log likelihood.}
\item{score}{Final value of the RP log likelihood gradient.}
\item{z}{Final search direction, a decaying linear function of previous score values.}
\item{S}{Logical vector of length n! indicating which elements of pi are greater than one.}
\item{n_iter}{Number of realized iterations.}
\item{score_range}{Difference between maximum and minimum gradient values
associated with positive elements of pi.}
\item{ln_maxl_diff}{Difference of RP log likelihood values between the
2nd last and last iterations.}
}
}
\description{
Using an algorithm for convex/concave programming on probability simplices,
iteratively find the maximum value of the RP log likelihood.
The basic algorithm is described in Chok and Vasil (2023) and a modification
to the algorithm to incorporate the momentum idea from the Machine Learning
literature is described in McCausland (unpub.)
While the RP log likelihood is concave in pi, for choice universes with more
than 3 elements, it is not strictly concave, pi is not identified and the
returned value of pi will depend on the starting value.
}
\examples{
library(RanCh)
n <- 5
u <- create_universe(n)
N <- vectorize_counts(u, RanCh::MMS_2019_counts[1, , ])
pi_ln_maxl <- compute_pi_ln_maxl(u, N)

}
\references{
McCausland, W. (2024). Sequential Monte Carlo for Random Prefernces. Unpublished manuscript.

Chok, J. and G. M. Vasil (2023). Convex Optimization over a Probability Simplex, arXiv:2305.09046
}
\author{
William McCausland, \email{william.j.mccausland@umontreal.ca}
}
